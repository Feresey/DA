\documentclass[12pt]{article}

\usepackage[utf8x]{inputenc}
\usepackage[T1, T2A]{fontenc}
\usepackage{fullpage}
\usepackage{multicol, multirow}
\usepackage{tabularx}
\usepackage{ulem}
\usepackage{listings} 
\usepackage[english, russian]{babel}
\usepackage{tikz}
\usepackage{pgfplots}
\usepackage{indentfirst}
\usepackage{noindentafter}
\usepackage{nonfloat}
\usepackage{ulem} 
\usepackage{fancyhdr}
% \usepackage{courier}
% \usepackage{FiraMono}
\usepackage{color}
\usepackage{subcaption}
\parindent=1cm


\parindent=1cm
\linespread{1}
\pgfplotsset{compat=1.16}
\newcommand{\se}[1]{\section*{\bf #1}}

\newcommand{\lst}[2]{
	\subsection*{\textbf{#2}}
	{\footnotesize
	\lstinputlisting[language=C++]{#1/#2}
	}
}
\lstdefinestyle{empty}{language=c++,
	basicstyle=\scriptsize,
	showspaces=false,
	showstringspaces=false,
	showtabs=false,
	tabsize=4,
	breaklines=true,
	escapechar=@,
	numbers=none,
	frame=none,
	escapeinside={\%*}{*)},
	breakatwhitespace=false % переносить строки только если есть пробел
}

\lstdefinestyle{customc}{
  belowcaptionskip=1\baselineskip,
  breaklines=true,
  frame=L,
  xleftmargin=\parindent,
  language=C++,
  numbers=left,
  showstringspaces=false,
  basicstyle=\footnotesize\ttfamily,
  keywordstyle=\bfseries\color{green!40!black},
  commentstyle=\itshape\color{purple!40!black},
  identifierstyle=\color{blue},
  stringstyle=\color{orange},
}

\lstset{escapechar=@,style=customc}

\begin{document}
\thispagestyle{empty}
\begin{center}
	\bfseries

	{\Large Московский авиационный институт\\ (национальный исследовательский университет)

	}

	\vspace{48pt}

	{\large Факультет информационных технологий и прикладной математики
	}

	\vspace{36pt}


	{\large Кафедра вычислительной математики и~программирования

	}


	\vspace{48pt}

	{Курсовой проект по курсу ``Дискретный анализ''}

\end{center}

\vspace{72pt}

\begin{flushright}
	\begin{tabular}{rl}
		Студент:       & П.\, А. Милько   \\
		Преподаватель: & А.\, А. Журавлёв \\
		Группа:        & М8О-208Б-17      \\
		Дата:          &                  \\
		Оценка:        &                  \\
		Подпись:       &                  \\
	\end{tabular}
\end{flushright}

\vfill

\begin{center}
	\bfseries
	Москва\\
	\the\year
\end{center}
\newpage
\setcounter{page}{1}

\se{Курсовой проект по теме: ``Аудио поиск''}

\subsection*{Запуск и параметры:}
\begin{lstlisting}[style=empty]
./prog index --input <input file> --output <index file>
./prog search --index <index file> --input <input file> --output <output file>
\end{lstlisting}

Входные файлы содержат в себе имена файлов с аудио записями по одному файлу в строке.

Результатом ответа на каждый запрос является строка с названием файла, с которым
произошло совпадение, либо строка ``! NOT FOUND'', если найти совпадение не удалось.

~
\smallbreak

\se{Описание}
\subsection*{Постановка задачи}

Задача состоит в применении быстрого преобразования Фурье для получения списка частот
из списка амплитуд. Уникальность аудио файлу дают как раз его частоты, а если точнее ---
самые громкие частоты. Это гарантирует, что если искомый аудио файл будет с посторонними
шумами, в плохом качестве и намного меньшего размера чем исходный, то всё равно можно
будет обнаружить совпадение с исходной записью. В теории можно ограничиться поиском
единственной максимальной частоты для конкретного временного отрезка в записи, но
логичнее искать несколько максимумов для разных диапазонов --- ударные инструменты,
голос, гитара, скрипка.

\subsection*{Дискретизация аналогового сигнала}

Преобразование аналогового сигнала в цифровой состоит из двух этапов: дискретизации
по времени и квантования по амплитуде. Дискретизация по времени означает, что сигнал
представляется рядом отсчетов (сэмплов), взятых через равные промежутки времени.
Например, если частота дискретизации $44100$, то это означает, что сигнал измеряется
$44100$ раз в течение одной секунды.

Чем больше частота, тем точнее соответствует цифровой сигнал аналоговому. Однако если
сделать частоту дискретизации слишком большой, то возрастёт плотность потока данных,
вычислительная нагрузка на процессоры и, конечно же, объём памяти, необходимый для хранения.

Считается, что человек слышит частоты в диапазоне от 20 до 20 000 Гц. Согласно
теореме Котельникова, для того, чтобы аналоговый (непрерывный по времени) сигнал можно
было точно восстановить по его отсчетам, частота дискретизации должна быть как минимум
вдвое больше максимальной звуковой частоты.

Сегодня самыми популярными частотами являются 44,1 кГц (CD) и 48 кГц (DAT).

Мной была использована частота 44100.

\subsection*{Обработка аудио файла}

Для получения списка отсчётов (семплов) была использована библиотека mpg123.

% \lst{../../kp}{main.cpp}
\begin{lstlisting}
template <size_t LENGTH, uint32_t STEP>
std::vector<float> Shazam<LENGTH, STEP>::processFile(const std::string& name)
{
	auto mh = mpg123_new(NULL, NULL);
	assert(mh != NULL);
	assert(mpg123_param(mh, MPG123_FLAGS, MPG123_MONO_MIX | MPG123_QUIET | MPG123_FORCE_FLOAT, 0.) == MPG123_OK);

	auto errorCode = mpg123_open(mh, name.c_str());
	assert(errorCode == MPG123_OK);
	long rate;
	int channels, encoding;
	errorCode = mpg123_getformat(mh, &rate, &channels, &encoding);
	assert(errorCode == MPG123_OK);
	if (rate != 44100) {
		mpg123_delete(mh);
		return {};
	}
	const size_t part_size = 1024;
	unsigned char part[part_size];
	size_t bytesRead;
	std::vector<float> samples;
	size_t bytesProcessed = 0;
	do {
		int err = mpg123_read(mh, part, part_size, &bytesRead);
		samples.resize((bytesProcessed + bytesRead) / 4 + 1);
		memcpy(reinterpret_cast<unsigned char*>(samples.data()) + bytesProcessed, part, bytesRead);
		bytesProcessed += bytesRead;
		if (err == MPG123_DONE)
			break;

		assert(err == MPG123_OK);
	} while (bytesRead > 0);
	samples.resize(bytesProcessed / 4);
	errorCode = mpg123_close(mh);
	assert(errorCode == MPG123_OK);
	mpg123_delete(mh);
	return samples;
}
\end{lstlisting}

Полученный вектор обрабатывается дискретным преобразованием Фурье по частям и с
некоторым шагом. Размер одной части по умолчанию равен 4096 элементов. Число было выбрано
степенью двойки не случайно, ибо так Фурье работает наиболее эффективно.

После обработки отрезка каждый его элемент будет соответствовать $44100/4096 \approx 11$ Герцам.
Шаг означает временное смещение при обработке аудио файла. Размер шага
напрямую влияет на скорость обработки и на точность при нахождении совпадений.
Чем меньше шаг --- тем дольше обработка и точнее совпадение.
Мной был выбран шаг 1024, что соответствует сдвигу в $1024/44100 \approx 0.02$ секунды
вдоль записи.

\subsection*{Составление базы данных}

\paragraph*{Выбранные диапазоны частот (в Герцах):}
40 --- 300 --- 800 --- 1500 -- 2700

И их относительное расположение на отрезке: ``3 27 74 139 250''

Итого одному отрезку будет соответствовать 4 числа --- самые громкие частоты из указанных
диапазонов. Используя эти максимумы и время начала отрезка относительно начала аудио файла
можно составить таблицу для поиска совпадений.

По полученным четырём числам можно вычислить хеш, который будет соответствовать только
такой последовательности чисел, например по формуле:

$hash(h_1,h_2,h_3,h_4) = h_1 + h_2 * (27 - 3)\\
	+h_3 * (74 -27)*(139-74)\\+h_4 * (74 -27)*(139-74)*(250 - 139)$\\
Тогда количество хешей будет ограничено числом\\
$(74 -27)*(139-74)*(250 - 139)*(274-250) = 8138520$

Такого количества достаточно для точной идентификации аудио файла, так как для 5-минутной
записи будет посчитано около 13000 хешей.

Соответственно для идентификации песни по её части нужно посчитать количество хешей,
совпадающих с исходной песней с некоторым смещением.

Сама же база данных будет состоять из двух таблиц --- одна будет состоять из ID файлов
(\lstinline{vector<vector<ID>>}),
а вторая из моментов времени вхождения хеша в песне (\lstinline{vector<vector<Time>>}).

Индекс каждого элемента в векторе --- это его хеш, а в самом элементе лежит вектор из
чисел.

% \newpage

\subsection*{Сжатие базы данных}
Итого соответствующие элементы таблиц будут выглядеть примерно так:
\begin{table}[ht!]
	\begin{tabular}{|l|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|}
		\hline
		ID   & 1 & 1 & 1 & 1 & 2 & 2 & 2  & 4 & 5 & 10 & 10 & 12 & 12 & 15 & 15 \\ \hline
		Time & 0 & 1 & 2 & 3 & 5 & 8 & 10 & 0 & 0 & 17 & 18 & 3  & 7  & 1  & 16 \\ \hline
	\end{tabular}
\end{table}

Можно было сделать не две таблицы, а одну --- состоящую из пар ``<ID, Time>'', но создание
двух таблиц оправданно, так как можно к каждой из них применить алгоритм сжатия simple9.

Этот алгоритм не изменяет способ представления данных, как, например, архиваторы, он лишь
позволяет оптимально использовать память для их записи.

Сам алгоритм состоит из двух частей: небольшая предварительная обработка числовой последовательности и
непосредственно запись в сжатой форме.

Первый шаг будет проще показать на примере. Пусть дана исходная последовательность
``1	1	1	1	2	2	2	4	5''. После обработки она
будет выглядеть следующим образом: ``1 0 0 0 1 0 0 2 1 5''. То есть вместо
каждого числа записывается его разница с предыдущим числом (первое число записывается неизменным).

Можно заметить что для записи любого из этих чисел будет достаточно 3 бита (число 5
как самое большое будет занимать 3 бита в двоичной форме). Это и есть суть сжатия в
simple9 оптимальное использование битового представления числа.

Для сжатия используются 32 байта (обычная 4-байтовая переменная типа int). Первые четыре
бита отдаются под служебные нужды (запись режима), остальные же 28 используются для
хранения чисел.

В примере выше мы получили последовательность ``1 0 0 0 1 0 0 2 1 5'' и
определили что для записи любого из её чисел будет достаточно 3 бита. Для записи чисел
могут быть использованы 28 бит, итого, если мы положим размер одного числа равным трём,
то сможем записать $28/3 = 9.33333$ чисел.
\begin{table}[ht]
	\begin{tabular}{|l|l|l|l|l|l|l|l|l|l|l|l|}
		\hline
		mode & 001 & 000 & 000 & 000 & 001 & 000 & 000 & 010 & 001 & 101 & 0 \\
		\hline
	\end{tabular}
\end{table}

Так будут выглядеть эти числа после сжатия. Но останется один неиспользованный бит,
``лишний''.

% \subsubsection*{Режимы:}

\begin{table}[ht]
	\caption*{Режимы:}
	\begin{tabular}{|l|c|c|c|c|c|c|c|c|c|}
		\hline
		Номер режима (mode)         & 1  & 2  & 3 & 4 & 5 & 6 & 7 & 8  & 9  \\ \hline
		Битовый размер числа        & 1  & 2  & 3 & 4 & 5 & 7 & 9 & 14 & 28 \\ \hline
		Количество чисел для записи & 28 & 14 & 9 & 7 & 5 & 4 & 3 & 2  & 1  \\ \hline
		Неиспользуемые биты         & 0  & 0  & 1 & 0 & 3 & 0 & 1 & 0  & 0  \\ \hline
	\end{tabular}
\end{table}


В примере выше номер режима будет равен 3, то есть первые 4 бита будут выглядеть так: 0011.

Этот метод сжатия будет очень эффективен для первой таблицы, так как в ней будет много
повторяющихся чисел, которые будут хорошо сжиматься. Для второй таблицы результат будет менее
впечатляющий --- последовательность чисел не всегда будет возрастающей и нельзя
будет применить оригинальную предварительную обработку, а числа будут возрастающими
последовательностями, в отличие от первой таблицы, где они были неубывающими, что тоже отрицательно влияет на степень сжатия.


Так же легко заметить, что при помощи simple9 невозможно записать числа большие чем $2^{28}$.
Хотя simple9 и прост для понимания, его реализация заняла по объёму столько же, сколько занимает
весь остальной курсовой проект.

\se{Описание реализации}

Начинается всё с обработки сигнала при помощи преобразования Фурье. Но, так как известно, что будут обрабатываться только действительные числовые
последовательности, можно использовать один трюк --- провести преобразование сразу для
двух последовательностей. Если записать первую последовательность в действительную часть
комплексного массива, а вторую --- в мнимую, то после преобразования Фурье из полученной
последовательности можно будет восстановить две исходные как будто к ним по отдельности
применили Фурье.  Функция DFFT запускает преобразование для двух последовательностей,
записанных в одну и разделяет их для дальнейшей обработки.

Функция GetHashes прогоняет вектор семплов через Фурье и получает наборы частот, на которых
ищет максимумы, и потом по ним считает хеш. Хеш заносится в базу данных.

Поиск осуществляется при помощи функций \_search и search. Первая составляет следующую
таблицу: \lstinline{map<SongID, map<TimeOffset, Count>>}. Это означает что для каждой
песни составляется таблица смещений по времени и для каждого смещения заводится счётчик
--- количество совпавших хешей для конкретной песни SongID, со смещением относительно начала
TimeOffset и счетчиком Count. Функция search лишь немного преобразовывает структуру,
полученную из первой функции: \lstinline{map<MatchPercent, pair<SongID, TimeOffset>>}.

\se{Исходный код}

%\lst{../../kp}{main.cpp}
%\lst{../../kp}{TComplex.hpp}
%\lst{../../kp}{SimpleVector.hpp}
%lst{../../kp}{Shazam.hpp}
%\lst{../../kp}{SimpleVector.h}
%\lst{../../kp}{Shazam.h}
\newpage

\se{Тестирование}

Известно, что формат записи mp3 не хранит данные несжатой форме, следовательно, на
извлечение данных требуется некоторое время.

При помощи утилиты gprof было выделено соотношение --- получение хешей из вектора
семплов примерно в 400 раз медленнее чем получение самих семплов.

\textbf{Тестовый запуск:}
\lst{../../kp}{search.txt}
\begin{lstlisting}[style=empty]
./kp index --input search.txt --output search.base
8138520
process file "pripev1.mp3" 
Song count: 1	hash count: 664
process file "pripev1_exo.mp3" 
Song count: 2	hash count: 666
process file "pripev2.mp3" 
Song count: 3	hash count: 858
process file "life_line.mp3" 
Song count: 4	hash count: 7850
process file "heart.mp3" 
Song count: 5	hash count: 10768
prepare to write...
WRITE!!!

./kp search --index search.base  --input search.txt --output outt
8138520
prepare to read...
READ!!!
process file "pripev1.mp3" 
hash count: 664
process file "pripev1_exo.mp3" 
hash count: 666
process file "pripev2.mp3" 
hash count: 858
process file "life_line.mp3" 
hash count: 7850
process file "heart.mp3" 
hash count: 10768
\end{lstlisting}
% \lst{../../kp}{outt}

Как можно увидеть, все аудио файлы были найдены.

Изначально составление базы песен происходило в 1 поток и при поиске песни
создавалась ещё одна база данных для записи её хешей. Также число самих хешей
было достаточно небольшим (порядка 2000), что очень негативно отразилось на
скорости поиска.

Запуск старой версии программы на файле с 13 файлами средней длительностью 5 минут:\\
\lstinline{./kp index --input ss --output ss.base  8,83s user 0,50s system 99% cpu 9,337 total}\\
\lstinline{./kp search --index ss.base --input ss --output outt  13,43s user 0,36s system 99% cpu 13,807 total}


Запуск конечной версии программы:\\
\lstinline{./kp index --input ss --output ss.base  14,19s user 0,82s system 531% cpu 2,825 total}\\
\lstinline{./kp search --index ss.base --input ss --output outt  9,36s user 0,58s system 99% cpu 9,959 total}

На больших файлах разница в скорости ещё больше в пользу конечного варианта. База из около
1000 песен обрабатывалась первым вариантом 15 минут, конечная же программа справилась за 5.

Поиск же ускорился ещё сильнее, в основном за счёт равномерного распределения хешей по таблице
(10000 хешей на песню и около 8 000 000 хешей на всю базу)

Немного об эффективности simple9: для базы из 1000 песен получилось 16782820
элементов на каждую из таблиц. Учитывая, что это переменные типа int, можно посчитать
сколько это будет занимать в памяти:
$16782820*4/1024/1024 \approx 64$ МБ

После обработки с помощью simple9 размер изменился всего до 9206818 элементов, или 
35 мегабайт.

Файлы с сильными шумами (запись части песни на микрофон телефона) тоже находятся, но
процент абсолютного совпадения по хешам очень мал (около 2-3\%), хотя и отличается от 
случайных совпадений (менее 0.5\%)

\begin{lstlisting}[style=empty,escapechar="]
process file "/dev/shm/1.mp3"
hash count: 878
match: 0.11%	name: "/home/lol/Music/Княzz/2005\_-\_Любовь\_негодяя/13.\_Летучий\_скелетик.mp3" time offset: 125.29
match: 0.23%	name: "/home/lol/Music/KiSh/Альбомы/1999\_-\_Акустический\_Альбом\_(четвёртое\_издание\_ОРТ-Рекордс,\_1999)/05.\_Девушка\_и\_Граф.mp3" time offset: 176.01
match: 0.34%	name: "/home/lol/Music/Сплин/+ Альбомы/1997 - Фонарь под глазом/02. Я не хочу домой.mp3" time offset: 11.94
match: 0.46%	name: "/home/lol/Music/Ария/Albums/2011\_-\_Феникс\_[Soyuz,\_SZCD\_7354-11,\_Russia]/08.\_Аттила.mp3" time offset: 54.24
match: 2.73%	name: "/home/lol/Music/Сплин/+ Альбомы/2009 - Сигнал из Космоса/12. Человек не спал.mp3" time offset: 25.10
\end{lstlisting}

В основном это происходит из-за моего выбора частотных диапазонов и из-за несовершенства
записывающей аппаратуры (мой микрофон практически не записывает низкие частоты). На 
представленной ниже спектрограмме можно это увидеть:\\
\includegraphics[scale=0.7]{original.jpg}\\
\includegraphics[scale=0.762]{phone.jpg}

Выше находится оригинальная спектрограмма, снизу её зашумленный отрезок. Частот ниже 1 000 Герц
практически нет, а учитывая что 3 из 4-х отрезков, для которых я ищу максимумы находятся
как раз в этом промежутке поиск совпадений представляется сомнительным и совпадение в
2.73\% уже настоящее чудо.


\newpage
\se{Выводы}

Я взял такую тему для курсового проекта ещё не зная про преобразование фурье и тем более
про simple9. Мне сказали что будет сложно, но интересно. Конечно же меня обманули.

Ничего сложного для понимания или реализации я не встретил, преобразование фурье довольно
часто используется и было несложно найти материалы, в отличие от simple9. Он не спроста
содержит простоту в своём названии --- найти в нём сложные места довольно сложно, однако
моя реализация получилась довольно громоздкой. Конечно же было бы эффективнее использовать
любой другой алгоритм сжатия, но и simple9 отлично справляется со своей задачей.

Фурье тоже может оказаться интересным, особенно если считать 2 фурье за одно. Конечно
нерекурсивная реализация может взорвать мозг своими перестановками, но это того стоит.

Конечно же не удалось достичь производительности оригинального шазама (со скрипом проходят файлы, которые были намеренно зашумлены), получилась лишь
сильно упрощённая версия, отражающая основную суть.


\end{document}
